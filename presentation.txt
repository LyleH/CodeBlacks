Hello. My name is ... and we are the Code Blacks.
We built a cloud app that solves one of our biggest inefficiencies here at Ambit Asset Finance.
We asked ... what our biggest inefficiency was and they said fixing test failures so that is problem we solved.
We wanted to quantify how much time and money was spent diagnosing and fixing test failures.
We asked 10 developers how much time they spent fixing tests and what was the maximum amount of time spent fixing a single test.
The results were...

So let's see this in action.
We tested our solution on an open source project called RestSharp, which has over 900 thousand downloads.
It gives developers easy access to internal or third-party web systems.
Here is a list of tests from RestSharp. You can see there are some failures.
Usually, if a developer has to fix a test, a large amount of effort and time can be spent diagnosing what broke the test.
Sometimes it is like trying to find a very small needle in a very large haystack.
Here at Ambit Asset Finance, we have millions of lines of source code and this changes about 100 times a day.
You can see there is an Analyze button beside this test.

So let's analyze it.
For our analysis, we need the tests files when the test last passed and the current test files with the broken test.
We zip these up and send them to our web server hosted by Azure in the cloud.
This saves the zip file to an Azure Storage location and adds a message to an Azure queue.
A background process picks up the message from the queue, retrieves the zip file and performs the comparison.
It does this by running the passing test and the failing test with code coverage, which provides which source code lines that the test used.
Once we have this information, we compare it and determine the differences.
We used OpenCover and ReportGenerator for code coverage and DiffPlex for some text comparisons.
We store the comparison report in Azure Storage and it is ready to be used by the developer.

So let's have a look at the results.
This is the old code and this is the new code.
Green means the line was executed by the test.
Light read means the line was not executed by test.
Dark red means something changed.
You can immediately see which line broke this test.
Normally a developer would have to do this manually and it might take them hours or days.

We thought this was a good result, but we didn't want you to take our word for it.
We went back to the developers we interviewed above and asked them what they thought about it and they said ...

In conclusion:
We identify one of the large development inefficiencies.
We created a solution to improve it by ...
We succeeded and developers can wait to use it.

Thanks for listening. I hope you enjoyed this presentation.